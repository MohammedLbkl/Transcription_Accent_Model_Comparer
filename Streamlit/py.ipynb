{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "883bf165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enregistrement audio pendant 10 secondes...\n",
      "Enregistrement terminé.\n",
      "Audio sauvegardé sous : mon_enregistrement.wav\n",
      "\n",
      "Lancement de la transcription...\n",
      "\n",
      "--- Transcription ---\n",
      "Thank you.\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import whisper\n",
    "import time # Pour la durée d'enregistrement\n",
    "\n",
    "# --- Votre fonction de transcription Whisper ---\n",
    "def whisper_transcription(file_path, model_name=\"tiny\"):\n",
    "    \"\"\"\n",
    "    Transcrit un fichier audio en utilisant OpenAI Whisper.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Chemin vers le fichier audio.\n",
    "        model_name (str): Nom du modèle Whisper à utiliser (ex: \"tiny\", \"base\", \"small\", \"medium\", \"large\").\n",
    "                          Les modèles plus grands sont plus précis mais plus lents et gourmands en ressources.\n",
    "    Returns:\n",
    "        str: Le texte transcrit.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = whisper.load_model(model_name)\n",
    "\n",
    "        # Charger l'audio et le préparer pour Whisper\n",
    "        audio = whisper.load_audio(file_path)\n",
    "        audio = whisper.pad_or_trim(audio) # S'assure que l'audio a la bonne longueur (30s)\n",
    "\n",
    "        # Calculer le spectrogramme log-Mel\n",
    "        # model.dims.n_mels donne le nombre de bandes Mel attendu par le modèle\n",
    "        mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "\n",
    "        # Définir les options de décodage\n",
    "        # fp16=False peut être nécessaire si vous n'avez pas de GPU compatible ou si vous rencontrez des erreurs.\n",
    "        options = whisper.DecodingOptions(fp16=False if model.device.type == 'cpu' else True) # fp16=False sur CPU\n",
    "\n",
    "        # Décoder l'audio\n",
    "        result = whisper.decode(model, mel, options)\n",
    "\n",
    "        return result.text\n",
    "    except Exception as e:\n",
    "        return f\"Erreur lors de la transcription : {e}\"\n",
    "\n",
    "# --- Fonction pour enregistrer l'audio ---\n",
    "def record_audio(filename=\"recorded_audio.wav\", record_seconds=5, rate=16000, chunk_size=1024, channels=1, audio_format=pyaudio.paInt16):\n",
    "    \"\"\"\n",
    "    Enregistre l'audio du microphone et le sauvegarde dans un fichier WAV.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Nom du fichier WAV de sortie.\n",
    "        record_seconds (int): Durée de l'enregistrement en secondes.\n",
    "        rate (int): Taux d'échantillonnage (Hz). Whisper préfère 16000 Hz.\n",
    "        chunk_size (int): Nombre de trames par buffer.\n",
    "        channels (int): Nombre de canaux audio (1 pour mono, 2 pour stéréo). Mono est suffisant pour la parole.\n",
    "        audio_format (pyaudio.paFormat): Format des échantillons audio.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    print(f\"Enregistrement audio pendant {record_seconds} secondes...\")\n",
    "\n",
    "    stream = p.open(format=audio_format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk_size)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(rate / chunk_size * record_seconds)):\n",
    "        try:\n",
    "            data = stream.read(chunk_size)\n",
    "            frames.append(data)\n",
    "        except IOError as e:\n",
    "            if e.errno == pyaudio.paInputOverflowed:\n",
    "                print(\"Avertissement : Input overflowed. Des données audio ont pu être perdues.\")\n",
    "                # On peut choisir de continuer ou d'ignorer ce chunk\n",
    "            else:\n",
    "                raise # Renvoyer d'autres IOErrors\n",
    "\n",
    "    print(\"Enregistrement terminé.\")\n",
    "\n",
    "    # Arrêter et fermer le flux\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Sauvegarder les données audio dans un fichier WAV\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(audio_format))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    print(f\"Audio sauvegardé sous : {filename}\")\n",
    "    return filename\n",
    "\n",
    "# --- Programme principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    output_filename = \"mon_enregistrement.wav\"\n",
    "    duration_seconds = 10  # Vous pouvez changer cette durée ou la demander à l'utilisateur\n",
    "\n",
    "    # Étape 1: Enregistrer l'audio\n",
    "    try:\n",
    "        recorded_file = record_audio(\n",
    "            filename=output_filename,\n",
    "            record_seconds=duration_seconds,\n",
    "            rate=16000,       # Whisper est optimisé pour 16kHz\n",
    "            channels=1        # Mono est généralement préférable pour la transcription vocale\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue lors de l'enregistrement : {e}\")\n",
    "        print(\"Vérifiez que vous avez un microphone connecté et que les permissions sont accordées.\")\n",
    "        exit()\n",
    "\n",
    "    # Étape 2: Transcrire l'audio enregistré\n",
    "    print(\"\\nLancement de la transcription...\")\n",
    "    # Vous pouvez choisir un autre modèle si besoin : \"base\", \"small\", \"medium\", \"large\"\n",
    "    # \"tiny\" est rapide mais moins précis. \"base\" est un bon compromis.\n",
    "    model_to_use = \"base\" # Essayez \"tiny\" si \"base\" est trop lent, ou \"small\" pour plus de précision\n",
    "    transcription = whisper_transcription(recorded_file, model_name=model_to_use)\n",
    "\n",
    "    print(\"\\n--- Transcription ---\")\n",
    "    print(transcription)\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    # Optionnel: Supprimer le fichier audio après transcription\n",
    "    # import os\n",
    "    # try:\n",
    "    #     os.remove(recorded_file)\n",
    "    #     print(f\"Fichier {recorded_file} supprimé.\")\n",
    "    # except OSError as e:\n",
    "    #     print(f\"Erreur lors de la suppression du fichier {recorded_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c866df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_ACCENT_MODEL = \"../notebooks/Whisper/modele_logistique.pkl\"  # Exemple: à remplacer\n",
    "PATH_TO_LABEL_ENCODER = \"../notebooks/Whisper/label_encoder.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511dbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242171e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pyaudio\n",
    "import wave\n",
    "import whisper\n",
    "import time\n",
    "import os\n",
    "import tempfile # Pour gérer les fichiers temporaires\n",
    "\n",
    "# --- Votre fonction de transcription Whisper (inchangée) ---\n",
    "def whisper_transcription(file_path, model_name=\"tiny\"):\n",
    "    try:\n",
    "        # Afficher un message pendant le chargement du modèle si ce n'est pas déjà fait\n",
    "        # (Whisper met en cache les modèles téléchargés)\n",
    "        with st.spinner(f\"Chargement du modèle Whisper '{model_name}'... (peut prendre du temps la première fois)\"):\n",
    "            model = whisper.load_model(model_name)\n",
    "\n",
    "        # st.info(f\"Modèle '{model_name}' chargé. Chargement de l'audio...\")\n",
    "        audio = whisper.load_audio(file_path)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "        # st.info(\"Calcul du spectrogramme log-Mel...\")\n",
    "        mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "\n",
    "        # st.info(\"Décodage de l'audio...\")\n",
    "        # fp16=False peut être nécessaire si vous n'avez pas de GPU compatible.\n",
    "        options = whisper.DecodingOptions(fp16=False if model.device.type == 'cpu' else True, language=\"fr\") # Spécifier la langue peut aider\n",
    "        result = whisper.decode(model, mel, options)\n",
    "\n",
    "        return result.text\n",
    "    except Exception as e:\n",
    "        st.error(f\"Erreur lors de la transcription Whisper : {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Fonction pour enregistrer l'audio (légèrement modifiée pour Streamlit) ---\n",
    "def record_audio(filename_prefix=\"temp_audio_streamlit\", record_seconds=5, rate=16000, chunk_size=1024, channels=1, audio_format=pyaudio.paInt16):\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Crée un fichier temporaire pour l'enregistrement\n",
    "    # delete=False car Whisper doit pouvoir ouvrir le fichier par son nom.\n",
    "    # Nous le supprimerons manuellement plus tard.\n",
    "    temp_file = tempfile.NamedTemporaryFile(prefix=filename_prefix, suffix=\".wav\", delete=False)\n",
    "    output_filename = temp_file.name\n",
    "    temp_file.close() # Fermer le handle pour que wave puisse l'ouvrir\n",
    "\n",
    "    # Message dans Streamlit\n",
    "    status_placeholder = st.empty()\n",
    "    status_placeholder.info(f\"🔴 Enregistrement en cours pendant {record_seconds} secondes... Parlez maintenant !\")\n",
    "\n",
    "    stream = p.open(format=audio_format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk_size)\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(rate / chunk_size * record_seconds)):\n",
    "        try:\n",
    "            data = stream.read(chunk_size)\n",
    "            frames.append(data)\n",
    "        except IOError as e:\n",
    "            if e.errno == pyaudio.paInputOverflowed:\n",
    "                print(\"Avertissement : Input overflowed. Des données audio ont pu être perdues.\")\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    status_placeholder.success(f\"✅ Enregistrement terminé. Sauvegarde en cours...\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(output_filename, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(audio_format))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    status_placeholder.empty() # Effacer le message de statut\n",
    "    return output_filename\n",
    "\n",
    "# --- Interface Streamlit ---\n",
    "st.set_page_config(page_title=\"Audio Transcriber\", layout=\"wide\")\n",
    "st.title(\"🎤 Enregistreur et Transcripteur Audio avec OpenAI Whisper\")\n",
    "st.markdown(\"Enregistrez un court message audio et obtenez sa transcription.\")\n",
    "\n",
    "# Initialiser l'état de session pour stocker le chemin du fichier et la transcription\n",
    "if \"audio_file_path\" not in st.session_state:\n",
    "    st.session_state.audio_file_path = None\n",
    "if \"transcription_text\" not in st.session_state:\n",
    "    st.session_state.transcription_text = \"\"\n",
    "\n",
    "# Options pour l'utilisateur\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    duration_seconds = st.slider(\n",
    "        \"Durée de l'enregistrement (secondes) :\",\n",
    "        min_value=3,\n",
    "        max_value=30, # Whisper fonctionne mieux sur des segments courts (max 30s par défaut)\n",
    "        value=5,\n",
    "        step=1\n",
    "    )\n",
    "with col2:\n",
    "    model_options = [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "    # \"large-v2\" ou \"large-v3\" si vous avez la dernière version de whisper\n",
    "    # model_options = [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\"]\n",
    "    selected_model = st.selectbox(\n",
    "        \"Choisissez le modèle Whisper :\",\n",
    "        options=model_options,\n",
    "        index=model_options.index(\"base\"), # \"base\" est un bon compromis\n",
    "        help=\"Les modèles plus grands sont plus précis mais plus lents et gourmands en ressources.\"\n",
    "    )\n",
    "\n",
    "# Bouton d'enregistrement et de transcription\n",
    "if st.button(\"🎙️ Démarrer l'enregistrement et Transcrire\", type=\"primary\", use_container_width=True):\n",
    "    # Nettoyer l'ancien fichier audio s'il existe\n",
    "    if st.session_state.audio_file_path and os.path.exists(st.session_state.audio_file_path):\n",
    "        try:\n",
    "            os.remove(st.session_state.audio_file_path)\n",
    "            # st.info(f\"Ancien fichier {st.session_state.audio_file_path} supprimé.\")\n",
    "        except Exception as e:\n",
    "            st.warning(f\"Impossible de supprimer l'ancien fichier audio : {e}\")\n",
    "    st.session_state.audio_file_path = None\n",
    "    st.session_state.transcription_text = \"\"\n",
    "\n",
    "    try:\n",
    "        # Étape 1: Enregistrer l'audio\n",
    "        with st.spinner(\"Préparation de l'enregistrement...\"):\n",
    "            recorded_file_path = record_audio(\n",
    "                record_seconds=duration_seconds,\n",
    "                rate=16000,\n",
    "                channels=1\n",
    "            )\n",
    "        st.session_state.audio_file_path = recorded_file_path\n",
    "        st.success(f\"Audio enregistré : {os.path.basename(recorded_file_path)}\")\n",
    "\n",
    "        # Étape 2: Transcrire l'audio enregistré\n",
    "        with st.spinner(f\"Transcription avec le modèle '{selected_model}' en cours... Ceci peut prendre un moment.\"):\n",
    "            transcription = whisper_transcription(st.session_state.audio_file_path, model_name=selected_model)\n",
    "\n",
    "        if transcription:\n",
    "            st.session_state.transcription_text = transcription\n",
    "        else:\n",
    "            st.session_state.transcription_text = \"La transcription a échoué ou n'a rien retourné.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"Une erreur globale est survenue : {e}\")\n",
    "        st.error(\"Vérifiez que vous avez un microphone connecté et que les permissions sont accordées. Consultez la console pour plus de détails.\")\n",
    "        # Nettoyer en cas d'erreur\n",
    "        if st.session_state.audio_file_path and os.path.exists(st.session_state.audio_file_path):\n",
    "            try:\n",
    "                os.remove(st.session_state.audio_file_path)\n",
    "            except: pass # Ignorer les erreurs de suppression ici\n",
    "        st.session_state.audio_file_path = None\n",
    "        st.session_state.transcription_text = \"\"\n",
    "\n",
    "\n",
    "# Afficher le lecteur audio et la transcription s'ils existent\n",
    "if st.session_state.audio_file_path and os.path.exists(st.session_state.audio_file_path):\n",
    "    st.subheader(\"🎧 Audio Enregistré :\")\n",
    "    try:\n",
    "        with open(st.session_state.audio_file_path, 'rb') as audio_file:\n",
    "            audio_bytes = audio_file.read()\n",
    "        st.audio(audio_bytes, format='audio/wav')\n",
    "    except Exception as e:\n",
    "        st.warning(f\"Impossible de charger le lecteur audio : {e}. Le fichier est peut-être corrompu ou a été supprimé.\")\n",
    "\n",
    "if st.session_state.transcription_text:\n",
    "    st.subheader(\"📝 Transcription :\")\n",
    "    st.text_area(\"Texte transcrit\", st.session_state.transcription_text, height=200,\n",
    "                 help=\"Vous pouvez copier ce texte.\")\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Application développée avec Streamlit et OpenAI Whisper.\")\n",
    "\n",
    "# Note sur le nettoyage :\n",
    "# Les fichiers temporaires créés avec delete=False ne sont pas automatiquement supprimés\n",
    "# à la fermeture du handle. Nous les supprimons au début d'un nouvel enregistrement.\n",
    "# Le dernier fichier créé pourrait rester jusqu'à ce que le système d'exploitation nettoie /tmp\n",
    "# ou que l'application soit redémarrée et qu'un nouvel enregistrement soit fait.\n",
    "# Pour une application en production, une stratégie de nettoyage plus robuste serait nécessaire."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
